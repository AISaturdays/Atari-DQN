{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import gym modules\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pytorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import time to slow down rendering speed\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create gym env\n",
    "env = gym.make('BreakoutDeterministic-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset it to return to the starting frame\n",
    "frame = env.reset()\n",
    "\n",
    "# render\n",
    "# uncomment in an environment that can render frames\n",
    "# env.render()\n",
    "\n",
    "# loop until done\n",
    "# random agent\n",
    "is_done = False\n",
    "while not is_done:\n",
    "    # Perform random action, return new frame, reward and whether the game is completed\n",
    "    frame, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "    # render next frame\n",
    "    # uncomment in an environment that can render frames\n",
    "    # env.render()\n",
    "\n",
    "    # time.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def q_iteration(env, model, state, iteration, memory):\n",
    "#     # select an epsilon for epsilon-greedy exploration vs exploitation\n",
    "#     epsilon = get_epsilon(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(2240, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(\"1\", x.shape)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "#         print(\"2\", x.shape)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        print(\"3\", x.shape)\n",
    "#         xx = x.view(1, -1)\n",
    "#         print(\"final\", x.shape)\n",
    "#         print(xx.shape)\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936868617320129\n",
      "0.9\n",
      "not random\n",
      "3 torch.Size([1, 32, 10, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1x1 (GPU 0)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "model = DQN()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(5000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    print(sample)\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    \n",
    "    print(eps_threshold)\n",
    "    if sample > eps_threshold:\n",
    "        print(\"not random\")\n",
    "        return model(Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        print(\"random\")\n",
    "        return LongTensor([[random.randrange(2)]])\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "# select_action(bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memory_test = ReplayMemory(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-46a6b1fff58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-8a02fe2167e6>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population"
     ]
    }
   ],
   "source": [
    "memory.sample(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_sync = 0\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    global last_sync\n",
    "    \n",
    "    # if population of the replay memory is not enough, don't do anything\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None, batch.next_state)))\n",
    "\n",
    "    # We don't want to backprop through the expected action values and volatile\n",
    "    # will save us on temporarily changing the model parameters'\n",
    "    # requires_grad to False!\n",
    "    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None]),\n",
    "                                     volatile=True)\n",
    "    state_batch = Variable(torch.cat(batch.state))\n",
    "    action_batch = Variable(torch.cat(batch.action))\n",
    "    reward_batch = Variable(torch.cat(batch.reward))\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = model(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = Variable(torch.zeros(BATCH_SIZE).type(Tensor))\n",
    "    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0]\n",
    "    # Now, we don't want to mess up the loss with a volatile flag, so let's\n",
    "    # clear it. After this, we'll just end up with a Variable that has\n",
    "    # requires_grad=False\n",
    "    next_state_values.volatile = False\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([2, 448])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(params)):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "( 1 ,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "( 2 ,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "... \n",
       "\n",
       "(207,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "(208,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "(209,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "[torch.FloatTensor of size 210x160x3]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_grayscale(img):\n",
    "    \"\"\"\n",
    "    turns an image into a grayscale image\n",
    "    \"\"\"\n",
    "    return np.mean(img, axis=2).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsample(img):\n",
    "    \"\"\"\n",
    "    downsamples an image by taking everyone second pixel\n",
    "    \"\"\"\n",
    "    return img[::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    preprocesses the image with grayscale and downsampling\n",
    "    \"\"\"\n",
    "    return to_grayscale(downsample(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_reward(reward):\n",
    "    \"\"\"\n",
    "    returns the sign of the reward, so that the learning agent can be used in multiple games\n",
    "    \"\"\"\n",
    "    return np.sign(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb71a94b0b8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhkhqMkRSkyGSmgyR1PR/RQkuakxu4DkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb71e6a9ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([142, 142, 142, 142, 142, 142, 142, 142,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 142, 142, 142,\n",
       "       142, 142, 142, 142], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_grayscale(frame)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.55686275,  0.55686275,  0.55686275, ...,  0.55686275,\n",
       "         0.55686275,  0.55686275],\n",
       "       [ 0.55686275,  0.55686275,  0.55686275, ...,  0.55686275,\n",
       "         0.55686275,  0.55686275],\n",
       "       [ 0.55686275,  0.55686275,  0.55686275, ...,  0.55686275,\n",
       "         0.55686275,  0.55686275]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(to_grayscale(frame)/255)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    for i in range(10):\n",
    "        action = env.action_space.sample()# take a random action\n",
    "        a,b,c,d = env.step(action)\n",
    "        plt.imshow(T.ToTensor())\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space.sample()# take a random action\n",
    "a,b,c,d = env.step(action)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-45fcb4719690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m resize = T.Compose([T.ToPILImage(),\n\u001b[0;32m----> 2\u001b[0;31m                     \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                     T.ToTensor()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Scale(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.Tensor(preprocess(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 105x80]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid permutation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-9e88736b1392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mpermute\u001b[0;34m(self, *dims)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Invalid permutation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid permutation"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean received an invalid combination of arguments - got (dtype=NoneType, axis=int, out=NoneType, ), but expected one of:\n * no arguments\n * (int dim, *, torch.FloatTensor out)\n * (int dim, bool keepdim, *, torch.FloatTensor out)\n      didn't match because some of the keywords were incorrect: dtype, axis\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3ff72034dab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-54dcc6b3d31c>\u001b[0m in \u001b[0;36mto_grayscale\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mturns\u001b[0m \u001b[0man\u001b[0m \u001b[0mimage\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgrayscale\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2952\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2954\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[0;31mTypeError\u001b[0m: mean received an invalid combination of arguments - got (dtype=NoneType, axis=int, out=NoneType, ), but expected one of:\n * no arguments\n * (int dim, *, torch.FloatTensor out)\n * (int dim, bool keepdim, *, torch.FloatTensor out)\n      didn't match because some of the keywords were incorrect: dtype, axis\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(to_grayscale(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function FloatTensor.unsqueeze>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "( 1 ,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "( 2 ,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "... \n",
       "\n",
       "(207,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "(208,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "\n",
       "(209,.,.) = \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "       ⋮       \n",
       "    0    0    0\n",
       "    0    0    0\n",
       "    0    0    0\n",
       "[torch.cuda.FloatTensor of size 210x160x3 (GPU 0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def get_screen(a):\n",
    "    print(a)\n",
    "    screen = a.transpose(\n",
    "        (2, 0, 1))  # transpose into torch order (CHW)\n",
    "    # Convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    print(screen.shape)\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).type(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "(3, 105, 80)\n"
     ]
    }
   ],
   "source": [
    "bb = get_screen(downsample(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 105, 80])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-5696500b722f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action[0, 0])\n",
    "        reward = Tensor([reward])\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(210, 160, 3)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    init_obs = env.reset()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action[0, 0])\n",
    "        reward = Tensor([reward])\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
